{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CNN with PyTorch\n",
    "\n",
    "This code is not complete.  It is merely a template for you to use as a guide. \n",
    "\n",
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "# this was tested with Windows python 3.7.8 64 bit kernel\n",
    "import sys\n",
    "! {sys.executable} -m pip install --upgrade torch\n",
    "! {sys.executable} -m pip install --upgrade torchvision\n",
    "\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other libraries we'll use\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ingest data using training and test loaders\n",
    "def load_dataset(data_path):\n",
    "    # Load all of the images\n",
    "    transformation = transforms.Compose([\n",
    "        # transform to tensors\n",
    "        # TODO\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root= # TODO,\n",
    "        transform= # TODO\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = # TODO\n",
    "    test_size = # TODO\n",
    "    train_dataset, test_dataset = torch.utils.data. # TODO\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        # TODO,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        # TODO,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Now load the images from the prepped image folder\n",
    "data_path = # TODO\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "print(classes)\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Neural Network Model\n",
    "\n",
    "The comments are merely _ideas_ on how to start this CNN...feel free to change anything you want to achieve better accuracies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. We'll apply 24 filters in the first convolutional layer\n",
    "        # TODO\n",
    "        \n",
    "        # A second convolutional layer takes 24 input channels, and generates 24 outputs\n",
    "        # TODO\n",
    "        \n",
    "        # A second convolutional layer takes 24 input channels, and generates 48 outputs\n",
    "        # TODO\n",
    "\n",
    "        # Apply max pooling with a kernel size of 2\n",
    "        # TODO\n",
    "                \n",
    "        # A drop layer deletes 50% of the features to help prevent overfitting\n",
    "        # TODO\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled three times with a kernel size of 2. 128/2/2/2 is 16.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 48 of them so our array is 16x16x48\n",
    "        # We need to flatten these and feed them to a fully-connected layer\n",
    "        # to map them to  the probability for each class\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after convolution 1 and pool\n",
    "        # TODO\n",
    "      \n",
    "        # Use a relu activation function after convolution 2 and pool\n",
    "        # TODO\n",
    "        \n",
    "        # Use a relu activation function after convolution 2)\n",
    "        # TODO\n",
    "        \n",
    "        # Use a relu activation function after convolution 2\n",
    "        # TODO\n",
    "        \n",
    "         # Use a relu activation function after convolution 3 and pool\n",
    "        # TODO\n",
    "        \n",
    "        # Select some features to drop to prevent overfitting\n",
    "        # TODO\n",
    "        \n",
    "        # Only drop the features if this is a training pass\n",
    "        # TODO\n",
    "        \n",
    "        # Flatten\n",
    "        # TODO\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        # TODO\n",
    "        # Return class probabilities via a log_softmax function \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(classes)).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "This will likely take awhile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(# TODO):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        # TODO\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        # TODO\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = # TODO\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.# TODO\n",
    "        optimizer.# TODO\n",
    "        \n",
    "        # Print metrics for every 10 batches so we see some progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    return train_loss / len(train_loader.dataset)\n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(# TODO)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += # TODO\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        # TODO\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return test_loss\n",
    "    \n",
    "    \n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = # TODO\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.# TODO\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 35 epochs\n",
    "epochs = 35\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = # TODO\n",
    "        test_loss = # TODO\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "model_file = 'gear-classifier.pth'\n",
    "torch.save(model.state_dict(), model_file)\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Delete the existing model variable\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Model with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to make image square\n",
    "def reshape_image(img, size): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # Convert RGBA images to RGB\n",
    "    if np.array(img).shape[2] == 4:\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "    # resize the image\n",
    "    img.thumbnail(size, Image.ANTIALIAS)\n",
    "    newimg = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    newimg.paste(img, (int((size[0] - img.size[0]) / 2), int((size[1] - img.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return np.array(newimg)\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image_array):\n",
    "    from PIL import Image\n",
    "   \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # These are the classes our model can predict\n",
    "    class_names = ['axes', 'boots', 'carabiners', 'crampons', 'gloves', 'hardshell_jackets', 'harnesses', 'helmets', 'insulated_jackets', 'pulleys', 'rope', 'tents']\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the imagees\n",
    "    image_tensor = torch.stack([transformation(image).float() for image in image_array])\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of each input image\n",
    "    predictions = classifier(input_features)\n",
    "    \n",
    "    predicted_classes = []\n",
    "    # Convert the predictions to a numpy array \n",
    "    for prediction in predictions.data.numpy():\n",
    "        # The prediction for each image is the probability for each class, e.g. [0.8, 0.1, 0.2]\n",
    "        # So get the index of the highest probability\n",
    "        class_idx = np.argmax(prediction)\n",
    "        # And append the corresponding class name to the results\n",
    "        predicted_classes.append(class_names[class_idx])\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "# Predict class for new data\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "image_urls = []\n",
    "image_urls.append('http://images.the-house.com/giro-g10mx-mtgy-07.jpg')\n",
    "image_urls.append('https://i.stack.imgur.com/HeliW.jpg')\n",
    "image_urls.append('https://productimages.camping-gear-outlet.com/e5/62379.jpg')\n",
    "image_urls.append('http://s7d1.scene7.com/is/image/MoosejawMB/MIKAJMKFMKCAPNABx1024698_zm?$product1000$')\n",
    "image_urls.append('http://ecx.images-amazon.com/images/I/41TNdO0o-LL._SX342_QL70_.jpg')\n",
    "\n",
    "size = (128,128)\n",
    "\n",
    "img_array = []\n",
    "\n",
    "for url_idx in range(len(image_urls)):\n",
    "    # Get the image\n",
    "    response = requests.get(image_urls[url_idx])\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = reshape_image(img, size)\n",
    "    img_array.append(img)\n",
    "    \n",
    "# Create a new model instance and load the weights\n",
    "model = Net(num_classes=len(classes))\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "predicted_classes = predict_image(model, np.array(img_array))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "idx = 0\n",
    "for predicted_class in predicted_classes:\n",
    "    a=fig.add_subplot(1,len(image_urls),idx+1)\n",
    "    img = img_array[idx]\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(predicted_class)\n",
    "    idx += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8bb34ad1b875d3161ce3302675f29779661d4a35ffbd1d17a3da28b3132449a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
